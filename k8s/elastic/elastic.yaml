

apiVersion: v1
kind: Namespace
metadata:
  name: infra-es


--- 

apiVersion: v1
kind: PersistentVolume
metadata: 
  name: pv-es-1
  namespace: infra-es
  labels: 
    app: es
    role: master
spec:
  capacity:
    storage: 20Gi
  volumeMode: Filesystem
  accessModes:
  # 可读可写，可被多个node挂载
  - ReadWriteMany
  # PVC删除时的回收策略: 保留
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage-class
  local:
    path: /var/virtual-volumes/es-1
  # 用于将local卷的pod调度到正确的位置
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        # 匹配结点标签值
        # 可通过 kubectl label node nodeName labelName=labelValue 设置标签
        # 可通过 kubectl get node --show-labels 查看标签
        # 可通过 kubectl label node nodename labelName- 删除标签
        - key: k8s.node.name
          # 匹配方式：In Exists
          operator: In
          values: 
          - master
          - node2

--- 

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-es-2
  namespace: infra-es
  labels:
    app: es
    role: master
spec:
  capacity:
    storage: 20Gi
  volumeMode: Filesystem
  accessModes:
  # 可读可写，可被多个node挂载
  - ReadWriteMany
  # PVC删除时的回收策略: 保留
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage-class
  local:
    path: /var/virtual-volumes/es-2
  # 用于将local卷的pod调度到正确的位置
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        # 匹配结点标签值
        # 可通过 kubectl label node nodeName labelName=labelValue 设置标签
        # 可通过 kubectl get node --show-labels 查看标签
        # 可通过 kubectl label node nodename labelName- 删除标签
        - key: k8s.node.name
          # 匹配方式：In Exists
          operator: In
          values:
          - master
          - node2

---

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: infra-es
  name: es-master-config
  labels:
    app: es
    role: master
data:
  elasticsearch.yml: |-
    cluster.name: ${CLUSTER_NAME}
    node.name: ${HOSTNAME}
    path.data: /esdata
    discovery.seed_hosts: ${NODE_LIST}
    cluster.initial_master_nodes: ${MASTER_NODES}
    network.host: 0.0.0.0
    node:
      # es节点的几个功能：用于协调的主节点，存储数据的节点，查询数据的节点，批量业务的节点（比如：定义一个pipeline，用于将所有提交数据的某个字段名map为新的名称，这样不用修改程序也可实现名称修改）
      # 节点是否有成为主节点资格
      master: true
      # 节点是否存储数据
      data: true
      # 节点是否作为批量作业节点，充当批量作业的节点，需要较多的内存
      ingest: true

    xpack.security.enabled: true
    xpack.monitoring.collection.enabled: true

---

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: es
  namespace: infra-es
spec:
  replicas: 2
  selector:
    matchLabels:
      app: es
      role: master
  serviceName: svc-es
  template:
    metadata:
      labels:
        app: es
        role: master
    spec:
      terminationGracePeriodSeconds: 10
      subdomain: es
      containers:
        - name: es
          image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
          # 镜像拉取策略
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9300   # 暴露的容器端口
              hostPort: 9300        # pod端口
              name: transport
            - containerPort: 9200
              hostPort: 9200
              name: client
          securityContext:
            runAsUser: 666
          env: 
            - name: ES_JAVA_OPTS
              value: -Xms736m -Xmx736m
            - name: APP_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NODE_LIST
              # replicas几个，这里就用几个IP
              # {hostname}.{service}.{namespace}.svc.cluster.local
              value: es-0.svc-es.infra-es.svc.cluster.local,es-1.svc-es.infra-es.svc.cluster.local
            - name: MASTER_NODES
              value: es-0,es-1
            - name: CLUSTER_NAME
              value: es
          #args:
          volumeMounts:
            - name: pvc-es
              mountPath: /esdata
            - name: config
              mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
              readOnly: true
              subPath: elasticsearch.yml
      volumes:
        - name: config
          configMap:
            name: es-master-config
  volumeClaimTemplates:
    - metadata:
        name: pvc-es
        namespace: infra-es
      spec:
        accessModes:
          - ReadWriteMany
        volumeMode: Filesystem
        resources:
          requests:
            storage: 20Gi
        storageClassName: local-storage-class
        selector:
          matchLabels:
            app: "es"
#          matchExpressions:
#            - {key: app, operator: In, values: [es]}

---

# 对外暴露的service

apiVersion: v1
kind: Service
metadata:
  name: svc-es
  namespace: infra-es
spec:
  # 要从外部访问服务，需要设定type，目前有：NodePort 和 Ingress，某些云服务商提供的k8s服务可能会提供其他类型，比如：LoadBalancer   
  # type: NodePort类型，需要指定具体端口，直接把服务暴露到宿主机的端口上，这时候k8s集群的每个节点(nodePort与port的区别，port只在本机器开端口)的物理主机上都会监听相应的端口
  # 由于node有可能挂掉，实际架构时固定的方式转发流量到固定的node IP上并不保险，所以有些云服务商的k8s服务在此基础上会提供负载均衡服务，能自动发现有哪些node（IP），并把流量负载均衡到node上
  # 如谷歌的：GCE，要完成这一步只需要将type: NodePort改为type: LoadBalancer （当然，得加钱）
  # Ingress类型，在k8s中部署nginx等转发程序，不在这里配置，它则需要再安装其他组件来支持（如：nginx/nginx-ingress），在安装了支持组件后，可通过 kind: Ingress 类型的发布来灵活调整转发流量的规则
  # 服务暴露的端口定义
  type: NodePort
  selector: 
    app: es
  ports:
    - name: es-web
      protocol: TCP
      # service端口
      port: 80
      # 指向pod的端口
      targetPort: 9200
      # 宿主机的端口，好像得从30000起，可在kube-apiserver.yaml调整
      nodePort: 32000
    - name: es-transport
      protocol: TCP
      port: 9300
      targetPort: 9300
